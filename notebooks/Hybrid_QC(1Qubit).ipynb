{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Qiskit v0.32.1 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Hybrid_QLDNN_QCQ_1000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU0dLKiHFf2j",
        "outputId": "1aa71df6-c317-4a6c-f20d-5a91c4dec32e"
      },
      "source": [
        "!pip install qiskit"
      ],
      "id": "zU0dLKiHFf2j",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-0.33.0.tar.gz (13 kB)\n",
            "Collecting qiskit-terra==0.19.0\n",
            "  Downloading qiskit_terra-0.19.0-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 9.2 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.9.1\n",
            "  Downloading qiskit_aer-0.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.9 MB 509 kB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.18.1\n",
            "  Downloading qiskit_ibmq_provider-0.18.1-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting qiskit-ignis==0.7.0\n",
            "  Downloading qiskit_ignis-0.7.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1->qiskit) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1->qiskit) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (1.24.3)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 984 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (2.8.2)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting retworkx>=0.8.0\n",
            "  Downloading retworkx-0.10.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.0->qiskit) (57.4.0)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.0->qiskit) (0.3.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.0->qiskit) (5.4.8)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting stevedore>=3.0.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting symengine>=0.8\n",
            "  Downloading symengine-0.8.1-cp37-cp37m-manylinux2010_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting python-constraint>=1.4\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "Collecting scipy>=1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.0->qiskit) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.18.1->qiskit) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (2.10)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 52.1 MB/s \n",
            "\u001b[?25hCollecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.1->qiskit) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.1->qiskit) (2.21)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 84.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.19.0->qiskit) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.19.0->qiskit) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.19.0->qiskit) (3.10.0.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.19.0->qiskit) (1.2.1)\n",
            "Building wheels for collected packages: qiskit, python-constraint\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.33.0-py3-none-any.whl size=11763 sha256=997c2395d7c2c66ca17d0c46141dbe11a0d37f00599602fa9ec2d3efce6ede34\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/60/ef/c49ae113df02818c4ade5fb6e2e89bb928625412eda0bb25f5\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=706fafb5d7e11522f463c86fff4c6590208a56e4bcc2869257f3822cf092b472\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
            "Successfully built qiskit python-constraint\n",
            "Installing collected packages: pbr, tweedledum, symengine, stevedore, scipy, retworkx, python-constraint, ply, ntlm-auth, cryptography, websocket-client, requests-ntlm, qiskit-terra, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cryptography-36.0.0 ntlm-auth-1.5.0 pbr-5.8.0 ply-3.11 python-constraint-1.4.0 qiskit-0.33.0 qiskit-aer-0.9.1 qiskit-ibmq-provider-0.18.1 qiskit-ignis-0.7.0 qiskit-terra-0.19.0 requests-ntlm-1.1.0 retworkx-0.10.2 scipy-1.7.3 stevedore-3.5.0 symengine-0.8.1 tweedledum-1.1.1 websocket-client-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b641b47-223d-4c7b-83da-22fafeb1ce30"
      },
      "source": [
        "#from IPython.core.debugger import set_trace\n",
        "import numpy as np\n",
        "\n",
        "# Importing standard Qiskit libraries\n",
        "from qiskit import QuantumCircuit, transpile, Aer, IBMQ\n",
        "from qiskit.tools.jupyter import *\n",
        "from qiskit.visualization import *\n",
        "#from ibm_quantum_widgets import *\n",
        "from qiskit.providers.aer import QasmSimulator\n",
        "\n",
        "# Loading your IBM Quantum account(s)\n",
        "#provider = IBMQ.load_account()"
      ],
      "id": "4b641b47-223d-4c7b-83da-22fafeb1ce30",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06531ccd-1b9f-4f08-8c98-d0cc9315f3f1"
      },
      "source": [
        "#Custom library\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "#sys.path.append(\"../Qiskit_Dynamic_Modelling\")\n",
        "#sys.path.append(\"./modelQ\")\n",
        "#sys.path.append(\"./dynamicsQ\")\n",
        "sys.path.append(\"./sample_data\")\n",
        "\n",
        "from visualize import *\n",
        "from ode_solver import *\n",
        "#from network import *\n",
        "from dataloader import *\n",
        "from lagrangian import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torchsummary import summary\n",
        "\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import qiskit\n",
        "from qiskit.circuit.random import random_circuit\n",
        "from qiskit import transpile, assemble"
      ],
      "id": "06531ccd-1b9f-4f08-8c98-d0cc9315f3f1",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ce742d-dff9-4cdc-b476-b0dad45658c6",
        "outputId": "d410cb89-ef34-4738-f678-cdf061fe8efb"
      },
      "source": [
        "print(\"--- Loading training and test data... ---\")\n",
        "train_data = np.load('/content/sample_data/train_dataset.npz')\n",
        "train_inputs = train_data[\"input\"]\n",
        "train_labels = train_data[\"labels\"]\n",
        "\n",
        "X_train = train_inputs[:1000]\n",
        "y_train = train_labels[:1000]\n",
        "\n",
        "#train_dataset = DynamicsDataset(train_inputs, train_labels)\n",
        "train_dataset = DynamicsDataset(X_train, y_train)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                 batch_size=1,\n",
        "                                                 shuffle=True,\n",
        "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
        "                                                 pin_memory=True,\n",
        "                                                 num_workers=1)\n",
        "test_data = np.load('/content/sample_data/val_dataset.npz')\n",
        "test_inputs = train_data[\"input\"]\n",
        "test_labels = train_data[\"labels\"]\n",
        "X_test = test_inputs[:1000]\n",
        "y_test = test_labels[:1000]\n",
        "\n",
        "test_dataset = DynamicsDataset(X_test, y_test)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                 batch_size=1,\n",
        "                                                 shuffle=False,\n",
        "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
        "                                                 pin_memory=True,\n",
        "                                                 num_workers=1)\n",
        "print(\"--- Loading training and test data completed ---\")"
      ],
      "id": "f3ce742d-dff9-4cdc-b476-b0dad45658c6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading training and test data... ---\n",
            "--- Loading training and test data completed ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4bb110b-3976-4cf4-aea4-3f554080bc40",
        "outputId": "9870e9f8-e58a-4479-9d62-95c8cf6663ca"
      },
      "source": [
        "for (X_train, y_train) in train_dataloader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    print('X_train:', X_train)\n",
        "    print('y_train:', y_train)\n",
        "    break\n",
        "\n",
        "for (X_test, y_test) in test_dataloader:\n",
        "    print('X_test:', X_test.size(), 'type:', X_test.type())\n",
        "    print('y_test:', y_test.size(), 'type:', y_test.type())\n",
        "    print('X_test:', X_test)\n",
        "    print('y_test:', y_test)\n",
        "    break"
      ],
      "id": "b4bb110b-3976-4cf4-aea4-3f554080bc40",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "y_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "X_train: tensor([[ 2.4841,  1.1141, -0.1981,  0.2497]], dtype=torch.float64)\n",
            "y_train: tensor([[-0.1981,  0.2497, -5.2559, -7.7180]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "y_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "X_test: tensor([[ 1.9537,  0.2797, -0.0780, -0.2268]], dtype=torch.float64)\n",
            "y_test: tensor([[-0.0780, -0.2268, -9.3138, -3.6618]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88f7c05-88f9-4f00-87cd-7c841835ed03"
      },
      "source": [
        "class QuantumCircuit:\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "        self.theta = qiskit.circuit.Parameter('theta')\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta, all_qubits)\n",
        "        \n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        #set_trace()\n",
        "        #print('cRun:',thetas)\n",
        "        List = [thetas]\n",
        "        t_qc = transpile(self._circuit,\n",
        "                         self.backend)\n",
        "        qobj = assemble(t_qc,\n",
        "                        shots=self.shots,\n",
        "                        parameter_binds = [{self.theta: theta} for theta in List])\n",
        "        #set_trace()\n",
        "        job = self.backend.run(qobj)\n",
        "        result = job.result().get_counts()\n",
        "        \n",
        "        counts = np.array(list(result.values()))\n",
        "        states = np.array(list(result.keys())).astype(float)\n",
        "        \n",
        "        # Compute probabilities for each state\n",
        "        probabilities = counts / self.shots\n",
        "        # Get state expectation\n",
        "        expectation = np.sum(states * probabilities)\n",
        "        \n",
        "        return np.array([expectation])"
      ],
      "id": "d88f7c05-88f9-4f00-87cd-7c841835ed03",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "83916b6d-f732-4ac2-88b1-3a47c4e3c858",
        "outputId": "1ef77fab-0752-45dc-df9d-39c622460157"
      },
      "source": [
        "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
        "\n",
        "circuit = QuantumCircuit(1, simulator, 100)\n",
        "#data = [2.1757166385650635]\n",
        "print('Expected value for rotation pi {}'.format(circuit.run(2.1757166385650635)))\n",
        "#print('Expected value for rotation pi {}'.format(circuit.run([1.4173])))\n",
        "circuit._circuit.draw()"
      ],
      "id": "83916b6d-f732-4ac2-88b1-3a47c4e3c858",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected value for rotation pi [0.9]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "     q: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 </pre>"
            ],
            "text/plain": [
              "        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "     q: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069a1e0d-f600-4109-ae0b-57ec65befdea"
      },
      "source": [
        "class HybridFunction(Function):\n",
        "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, input, quantum_circuit, shift):\n",
        "        \"\"\" Forward pass computation \"\"\"\n",
        "        ##print('hFor:', input)\n",
        "        #print('hFor1:', input[0])\n",
        "        #print('hFor2:', input[0].tolist())\n",
        "        ctx.shift = shift\n",
        "        ctx.quantum_circuit = quantum_circuit\n",
        "        #expectation_z = []\n",
        "        #for i in range(len(input)):\n",
        "        #    expectation_z.append(ctx.quantum_circuit.run(input[i].tolist()))\n",
        "        #print('expectation_z',expectation_z)\n",
        "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
        "        result = torch.tensor([expectation_z])\n",
        "        #result = torch.tensor(expectation_z)\n",
        "        ctx.save_for_backward(input, result)\n",
        "\n",
        "        return result\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\" Backward pass computation \"\"\"\n",
        "        input, expectation_z = ctx.saved_tensors\n",
        "        input_list = np.array(input.tolist())\n",
        "        \n",
        "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
        "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
        "        \n",
        "        gradients = []\n",
        "        for i in range(len(input_list)):\n",
        "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
        "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
        "            \n",
        "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
        "            gradients.append(gradient)\n",
        "        gradients = np.array([gradients]).T\n",
        "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
        "\n",
        "class Hybrid(nn.Module):\n",
        "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
        "    \n",
        "    def __init__(self, backend, shots, shift):\n",
        "        super(Hybrid, self).__init__()\n",
        "        self.quantum_circuit = QuantumCircuit(1, backend, shots)\n",
        "        self.shift = shift\n",
        "        \n",
        "    def forward(self, input):\n",
        "        #print('3',input)\n",
        "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
      ],
      "id": "069a1e0d-f600-4109-ae0b-57ec65befdea",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35542acb-5d1a-49c0-a68b-34ac5abfa671"
      },
      "source": [
        "class LagrangianNeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, D_in, hidden_list, D_out):\n",
        "        \"\"\"\n",
        "        Neural Network used to approximate a paramaterized system lagrangian\n",
        "        \"\"\"\n",
        "        super(LagrangianNeuralNetwork, self).__init__()\n",
        "        self.model_layers = torch.nn.ModuleList()\n",
        "\n",
        "        # input layer\n",
        "        self.model_layers.append(torch.nn.Linear(D_in, hidden_list[0]))\n",
        "        # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[0]))\n",
        "        self.model_layers.append(torch.nn.Softplus())\n",
        "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
        "        # add all hiden layers\n",
        "        for i in range(1, len(hidden_list)):\n",
        "            self.model_layers.append(torch.nn.Linear(hidden_list[i-1], hidden_list[i]))\n",
        "            # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[i]))\n",
        "            self.model_layers.append(torch.nn.Softplus())\n",
        "\n",
        "        #self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
        "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
        "        # output layer\n",
        "        self.model_layers.append(torch.nn.Linear(hidden_list[-1], D_out))\n",
        "        self.model_layers.append(torch.nn.Softplus())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        applies all of the model layers, and returns the single output value,\n",
        "        which in this case is the lagrangian of the system, representing the\n",
        "        total energy\n",
        "        \"\"\"\n",
        "        for layer in self.model_layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "id": "35542acb-5d1a-49c0-a68b-34ac5abfa671",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d2bedba-0e01-4403-8535-b54d702ca1cc",
        "outputId": "780f222c-7add-46e1-a2a3-e682aee10270"
      },
      "source": [
        "# determine device\n",
        "print(\"--- Checking for CUDA Device... ---\")\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "id": "9d2bedba-0e01-4403-8535-b54d702ca1cc",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking for CUDA Device... ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvkMDk12QBHo",
        "outputId": "149f1284-d24a-4a31-8e54-3555e2d5ce25"
      },
      "source": [
        "# organize data\n",
        "input_size = train_inputs.shape[1]\n",
        "output_size = 1  # for all lagrangian systems, output should be just a scalar energy value\n",
        "\n",
        "# build model\n",
        "print(\"--- Constructing Model... ---\")\n",
        "D_in = input_size  # state size\n",
        "# hidden_list = [D_in, 256, 256, 256, 256, 256]\n",
        "hidden_list = [D_in, 32, 64, 128, 256, 512, 256, 128, 64, 32]\n",
        "D_out = output_size\n",
        "lnn_model = LagrangianNeuralNetwork(D_in, hidden_list, D_out)\n",
        "#summary(lnn_model, (1, 28, 28), device='cpu')\n",
        "# set up training parameters\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "momentum = 0.9\n",
        "num_epochs = 20\n",
        "optimizer = torch.optim.Adam(lnn_model.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=weight_decay)\n",
        "\n",
        "if os.path.isfile(\"model_weights.pth\"):\n",
        "    print(\"Re-loading existing weights!\")\n",
        "    checkpoint = torch.load(\"model_weights.pth\")\n",
        "    lnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# ensure model is in train mode so gradients are properly calculated\n",
        "lnn_model.train()\n",
        "# load device to either GPU or CPU depending on hardware\n",
        "lnn_model.to(device)\n",
        "\n",
        "# set up loss function\n",
        "loss_fcn = torch.nn.MSELoss()\n",
        "\n",
        "# set up GradScaler to improve run speed\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "id": "LvkMDk12QBHo",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Constructing Model... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56359ff6-9cbd-4491-b2ab-9001b5342048",
        "outputId": "a8ef7622-ea0c-41b6-b8ec-60af926e6c0c"
      },
      "source": [
        "import time\n",
        "print(\"--- Beginning Training! ---\")\n",
        "loss_listQCQ = []\n",
        "lnn_model.train()\n",
        "startTimeQCQ = time.time()\n",
        "print('Training Start Time (in sec) : ',(startTimeQCQ))\n",
        "print('Training Start Time : ',(time.asctime( time.localtime(time.time()) )))\n",
        "for epoch in range(num_epochs):\n",
        "    total_lossQCQ = []\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        for p in lnn_model.parameters(): p.grad = None\n",
        "        # Forward pass\n",
        "        #output = model(data)\n",
        "        # Calculating loss\n",
        "        #loss = loss_func(output, target)\n",
        "        # output from model is the energy calculated from the parameterized lagrangian\n",
        "        #print('1',data)\n",
        "        #print('1',data.detach().numpy())\n",
        "        #for val in enumerate(data.detach().numpy()):\n",
        "        #    print(val)\n",
        "        Listk = []\n",
        "        for val in data.detach().numpy():\n",
        "            #print(val)            \n",
        "            for i in range(len(val)):\n",
        "                #print(val[i])\n",
        "                qcr = circuit.run(val[i])\n",
        "                #print(qcr[0])\n",
        "                Listk.append(qcr[0])\n",
        "                #print(Listk)\n",
        "                \n",
        "        ListTarget = []\n",
        "        #print(target)\n",
        "        for valT in target.detach().numpy():\n",
        "            #print(val)            \n",
        "            for j in range(len(valT)):\n",
        "                #print(val[i])\n",
        "                qcrT = circuit.run(valT[j])\n",
        "                #print(qcr[0])\n",
        "                ListTarget.append(qcrT[0])\n",
        "                #print(ListTarget)\n",
        "        targetData = torch.tensor(ListTarget)\n",
        "        data = torch.squeeze(torch.tensor(Listk))\n",
        "        #data = torch.squeeze(data)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            target_pred = solve_euler_lagrange(lnn_model.forward, data.float())\n",
        "            #print('1',target_pred)\n",
        "            #print('2',target.float())\n",
        "            loss = loss_fcn(target_pred.unsqueeze(0), targetData.float())\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        # Optimize the weights\n",
        "        scaler.step(optimizer)\n",
        "        # update the scale for next iteration\n",
        "        scaler.update()\n",
        "\n",
        "        #print(\"Iter Num: \", batch_idx)\n",
        "        '''\n",
        "        if (batch_idx == 10):\n",
        "            #print(\"Iter Num: \", batch_idx)\n",
        "            break\n",
        "        '''\n",
        "        #print(\"Iter Num: \", len(train_dataloader))\n",
        "        #print(\"Iter Num: \", batch_idx)\n",
        "        total_lossQCQ.append(loss.item())\n",
        "    loss_listQCQ.append(sum(total_lossQCQ)/len(total_lossQCQ))\n",
        "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
        "        100. * (epoch + 1) / num_epochs, loss_listQCQ[-1]))\n",
        "print('Training End Time (in sec) : ',(time.time()))\n",
        "print('Total training time (in sec)', ((time.time() - startTimeQCQ)))\n",
        "print('Training End Time',(time.asctime( time.localtime(time.time()) )))\n",
        "print('end')"
      ],
      "id": "56359ff6-9cbd-4491-b2ab-9001b5342048",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Beginning Training! ---\n",
            "Training Start Time (in sec) :  1639001956.168983\n",
            "Training Start Time :  Wed Dec  8 22:19:16 2021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [5%]\tLoss: 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [10%]\tLoss: 0.0704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [15%]\tLoss: 0.0683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [20%]\tLoss: 0.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [25%]\tLoss: 0.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [30%]\tLoss: 0.0644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [35%]\tLoss: 0.0645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [40%]\tLoss: 0.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [45%]\tLoss: 0.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [50%]\tLoss: 0.0637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [55%]\tLoss: 0.0621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [60%]\tLoss: 0.0621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [65%]\tLoss: 0.0617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [70%]\tLoss: 0.0619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [75%]\tLoss: 0.0616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [80%]\tLoss: 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [85%]\tLoss: 0.0618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [90%]\tLoss: 0.0612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [95%]\tLoss: 0.0613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [100%]\tLoss: 0.0618\n",
            "Training End Time (in sec) :  1639004304.6900856\n",
            "Total training time (in sec) 2348.521541595459\n",
            "Training End Time Wed Dec  8 22:58:24 2021\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4aa85bc5-b9d3-49a3-9c42-7b960831a5c8",
        "outputId": "5a52c5c0-57f6-487c-b916-690d47aa064a"
      },
      "source": [
        "plt.plot(loss_listQCQ)\n",
        "plt.title('Hybrid LQNN Q-C Training (Using single qubit circuit)')\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Loss')\n",
        "#plt.show()"
      ],
      "id": "4aa85bc5-b9d3-49a3-9c42-7b960831a5c8",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b07d24fd-d4b8-4212-9071-1f2e78a3413b",
        "outputId": "01f799ce-cd9e-4f38-b1b6-d288e3fcf6cc"
      },
      "source": [
        "print(\"--- Beginning Test! ---\")\n",
        "lnn_model.eval()\n",
        "total_losstestQCQ = []\n",
        "correctQCQ = 0\n",
        "for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data = torch.squeeze(data)\n",
        "    with torch.cuda.amp.autocast():\n",
        "        target_pred = solve_euler_lagrange(lnn_model.forward, data.float())\n",
        "        #print(target_pred)\n",
        "        #print(target)\n",
        "        correctQCQ += target_pred.eq(target.view_as(target_pred)).sum().item()\n",
        "        loss = loss_fcn(target_pred.unsqueeze(0), target.float())        \n",
        "    total_losstestQCQ.append(loss.item())\n",
        "batch_size = 1\n",
        "print('Performance on test data:[{:.0f}%]\\tLoss: {:.4f}\\tAccuracy: {:.1f}%'.format(\n",
        "    100. * (epoch + 1) / num_epochs,\n",
        "    sum(total_losstestQCQ) / len(total_losstestQCQ),\n",
        "    correctQCQ / len(test_dataloader) * 100 / batch_size)\n",
        "    )\n",
        "\n",
        "print('end')"
      ],
      "id": "b07d24fd-d4b8-4212-9071-1f2e78a3413b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Beginning Test! ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "/usr/local/lib/python3.7/dist-packages/qiskit/utils/deprecation.py:62: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance on test data:[100%]\tLoss: 22.0757\tAccuracy: 0.0%\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04928beb-aa4d-48e1-a823-e1a61b9ca15d"
      },
      "source": [
        ""
      ],
      "id": "04928beb-aa4d-48e1-a823-e1a61b9ca15d",
      "execution_count": null,
      "outputs": []
    }
  ]
}