{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b641b47-223d-4c7b-83da-22fafeb1ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2021-11-19 01:21:31,034: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "\n",
    "# Importing standard Qiskit libraries\n",
    "from qiskit import QuantumCircuit, transpile, Aer, IBMQ\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from ibm_quantum_widgets import *\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "\n",
    "# Loading your IBM Quantum account(s)\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06531ccd-1b9f-4f08-8c98-d0cc9315f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom library\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../Qiskit_Dynamic_Modelling\")\n",
    "sys.path.append(\"./modelQ\")\n",
    "sys.path.append(\"./dynamicsQ\")\n",
    "\n",
    "from visualize import *\n",
    "from ode_solver import *\n",
    "#from network import *\n",
    "from dataloader import *\n",
    "from lagrangian import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import qiskit\n",
    "from qiskit.circuit.random import random_circuit\n",
    "from qiskit import transpile, assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3ce742d-dff9-4cdc-b476-b0dad45658c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading training and test data... ---\n",
      "--- Loading training and test data completed ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Loading training and test data... ---\")\n",
    "train_data = np.load('train_dataset.npz')\n",
    "train_inputs = train_data[\"input\"]\n",
    "train_labels = train_data[\"labels\"]\n",
    "\n",
    "train_dataset = DynamicsDataset(train_inputs, train_labels)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=True,\n",
    "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
    "                                                 pin_memory=True,\n",
    "                                                 num_workers=1)\n",
    "test_data = np.load('val_dataset.npz')\n",
    "test_inputs = train_data[\"input\"]\n",
    "test_labels = train_data[\"labels\"]\n",
    "test_dataset = DynamicsDataset(test_inputs, test_labels)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=False,\n",
    "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
    "                                                 pin_memory=True,\n",
    "                                                 num_workers=1)\n",
    "print(\"--- Loading training and test data completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4bb110b-3976-4cf4-aea4-3f554080bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
      "y_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
      "X_train: tensor([[-2.0779,  0.2821, -0.2493, -0.0690]], dtype=torch.float64)\n",
      "y_train: tensor([[-0.2493, -0.0690, 10.1490,  4.4292]], dtype=torch.float64)\n",
      "X_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
      "y_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
      "X_test: tensor([[ 1.9537,  0.2797, -0.0780, -0.2268]], dtype=torch.float64)\n",
      "y_test: tensor([[-0.0780, -0.2268, -9.3138, -3.6618]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_dataloader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    print('X_train:', X_train)\n",
    "    print('y_train:', y_train)\n",
    "    break\n",
    "\n",
    "for (X_test, y_test) in test_dataloader:\n",
    "    print('X_test:', X_test.size(), 'type:', X_test.type())\n",
    "    print('y_test:', y_test.size(), 'type:', y_test.type())\n",
    "    print('X_test:', X_test)\n",
    "    print('y_test:', y_test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d88f7c05-88f9-4f00-87cd-7c841835ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\" \n",
    "    This class provides a simple interface for interaction \n",
    "    with the quantum circuit \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        set_trace()\n",
    "        print('cRun:',thetas)\n",
    "        t_qc = transpile(self._circuit,\n",
    "                         self.backend)\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
    "        #set_trace()\n",
    "        job = self.backend.run(qobj)\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array(list(result.keys())).astype(float)\n",
    "        \n",
    "        # Compute probabilities for each state\n",
    "        probabilities = counts / self.shots\n",
    "        # Get state expectation\n",
    "        expectation = np.sum(states * probabilities)\n",
    "        \n",
    "        return np.array([expectation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "83916b6d-f732-4ac2-88b1-3a47c4e3c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cRun: [3.141592653589793]\n",
      "> \u001b[0;32m/tmp/ipykernel_7598/3735393921.py\u001b[0m(32)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     30 \u001b[0;31m                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 32 \u001b[0;31m        \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Expected value for rotation pi 0.46\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 417.879x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "\n",
    "circuit = QuantumCircuit(1, simulator, 100)\n",
    "print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
    "circuit._circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "069a1e0d-f600-4109-ae0b-57ec65befdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        print('hFor:', input)\n",
    "        print('hFor1:', input[0])\n",
    "        print('hFor2:', input[0].tolist())\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients.append(gradient)\n",
    "        gradients = np.array([gradients]).T\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(1, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        print(input)\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35542acb-5d1a-49c0-a68b-34ac5abfa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagrangianNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, D_in, hidden_list, D_out):\n",
    "        \"\"\"\n",
    "        Neural Network used to approximate a paramaterized system lagrangian\n",
    "        \"\"\"\n",
    "        super(LagrangianNeuralNetwork, self).__init__()\n",
    "        self.model_layers = torch.nn.ModuleList()\n",
    "\n",
    "        # input layer\n",
    "        self.model_layers.append(torch.nn.Linear(D_in, hidden_list[0]))\n",
    "        # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[0]))\n",
    "        self.model_layers.append(torch.nn.Softplus())\n",
    "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
    "        # add all hiden layers\n",
    "        for i in range(1, len(hidden_list)):\n",
    "            self.model_layers.append(torch.nn.Linear(hidden_list[i-1], hidden_list[i]))\n",
    "            # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[i]))\n",
    "            self.model_layers.append(torch.nn.Softplus())\n",
    "\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
    "        # output layer\n",
    "        self.model_layers.append(torch.nn.Linear(hidden_list[-1], D_out))\n",
    "        self.model_layers.append(torch.nn.Softplus())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        applies all of the model layers, and returns the single output value,\n",
    "        which in this case is the lagrangian of the system, representing the\n",
    "        total energy\n",
    "        \"\"\"\n",
    "        print(\"abhi: \", x)\n",
    "        for layer in self.model_layers:\n",
    "            #print(layer)\n",
    "            x = self.hybrid(x)\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9d2bedba-0e01-4403-8535-b54d702ca1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for CUDA Device... ---\n"
     ]
    }
   ],
   "source": [
    "# determine device\n",
    "print(\"--- Checking for CUDA Device... ---\")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56359ff6-9cbd-4491-b2ab-9001b5342048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Constructing Model... ---\n",
      "Re-loading existing weights!\n",
      "--- Beginning Training! ---\n",
      "abhi:  tensor([ 2.1757,  0.3863, -0.1316, -0.1969], grad_fn=<ViewBackward>)\n",
      "tensor([ 2.1757,  0.3863, -0.1316, -0.1969], grad_fn=<ViewBackward>)\n",
      "hFor: tensor([ 2.1757,  0.3863, -0.1316, -0.1969], grad_fn=<ViewBackward>)\n",
      "hFor1: tensor(2.1757, requires_grad=True)\n",
      "hFor2: 2.1757166385650635\n",
      "> \u001b[0;32m/tmp/ipykernel_7598/4051556334.py\u001b[0m(26)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cRun:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        t_qc = transpile(self._circuit,\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m                         self.backend)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cRun: 2.1757166385650635\n",
      "> \u001b[0;32m/tmp/ipykernel_7598/4051556334.py\u001b[0m(27)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cRun:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        t_qc = transpile(self._circuit,\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m                         self.backend)\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        qobj = assemble(t_qc,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_7598/4051556334.py\u001b[0m(28)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cRun:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        t_qc = transpile(self._circuit,\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m                         self.backend)\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        qobj = assemble(t_qc,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                        \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_7598/4051556334.py\u001b[0m(27)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cRun:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        t_qc = transpile(self._circuit,\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m                         self.backend)\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        qobj = assemble(t_qc,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_7598/4051556334.py\u001b[0m(29)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m        t_qc = transpile(self._circuit,\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m                         self.backend)\n",
      "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m        qobj = assemble(t_qc,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                        \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  thetas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1757166385650635\n"
     ]
    }
   ],
   "source": [
    "# organize data\n",
    "input_size = train_inputs.shape[1]\n",
    "output_size = 1  # for all lagrangian systems, output should be just a scalar energy value\n",
    "\n",
    "# build model\n",
    "print(\"--- Constructing Model... ---\")\n",
    "D_in = input_size  # state size\n",
    "# hidden_list = [D_in, 256, 256, 256, 256, 256]\n",
    "hidden_list = [D_in, 32, 64, 128, 256, 512, 256, 128, 64, 32]\n",
    "D_out = output_size\n",
    "lnn_model = LagrangianNeuralNetwork(D_in, hidden_list, D_out)\n",
    "#summary(lnn_model, (1, 28, 28), device='cpu')\n",
    "# set up training parameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "momentum = 0.9\n",
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(lnn_model.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "\n",
    "if os.path.isfile(\"model_weights.pth\"):\n",
    "    print(\"Re-loading existing weights!\")\n",
    "    checkpoint = torch.load(\"model_weights.pth\")\n",
    "    lnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# ensure model is in train mode so gradients are properly calculated\n",
    "lnn_model.train()\n",
    "# load device to either GPU or CPU depending on hardware\n",
    "lnn_model.to(device)\n",
    "\n",
    "# set up loss function\n",
    "loss_fcn = torch.nn.MSELoss()\n",
    "\n",
    "# set up GradScaler to improve run speed\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(\"--- Beginning Training! ---\")\n",
    "loss_list = []\n",
    "lnn_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        for p in lnn_model.parameters(): p.grad = None\n",
    "        # Forward pass\n",
    "        #output = model(data)\n",
    "        # Calculating loss\n",
    "        #loss = loss_func(output, target)\n",
    "        # output from model is the energy calculated from the parameterized lagrangian\n",
    "        data = torch.squeeze(data)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            target_pred = solve_euler_lagrange(lnn_model.forward, data.float())\n",
    "            loss = loss_fcn(target_pred.unsqueeze(0), target.float())\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        # Optimize the weights\n",
    "        scaler.step(optimizer)\n",
    "        print(\"Iter Num: \", batch_idx)\n",
    "        if (batch_idx == 10):\n",
    "            print(\"Iter Num: \", batch_idx)\n",
    "            break\n",
    "        #print(\"Iter Num: \", len(train_dataloader))\n",
    "        #print(\"Iter Num: \", batch_idx)\n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / num_epochs, loss_list[-1]))\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33dd46e8-d457-4823-9f56-344bfa3a5607",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7598/968409142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtarget_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_euler_lagrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Qiskit_Dynamic_Modelling/./dynamicsQ/lagrangian.py\u001b[0m in \u001b[0;36msolve_euler_lagrange\u001b[0;34m(lagrange_fcn, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# The hessian/jacobian are calculated w.r.t all variables in xv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# so select only relevant parts using slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlagrange_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlagrange_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlagrange_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    476\u001b[0m                                           \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjac_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_single_output_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jacobian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    476\u001b[0m                                           \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mensure_single_output_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mis_out_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hessian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7598/3262174656.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#print(layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7598/3534493723.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mHybridFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7598/3534493723.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, quantum_circuit, shift)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantum_circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mexpectation_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpectation_z\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7598/2147858849.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     28\u001b[0m         qobj = assemble(t_qc,\n\u001b[1;32m     29\u001b[0m                         \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                         parameter_binds = [{self.theta: theta} for theta in thetas])\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4d471-de53-4624-ae73-0c8c9d3be4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qiskit v0.32.0 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
