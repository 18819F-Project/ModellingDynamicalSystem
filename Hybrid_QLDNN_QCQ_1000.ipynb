{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Qiskit v0.32.1 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Hybrid_QLDNN_QCQ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU0dLKiHFf2j",
        "outputId": "1bb0ca47-34c6-4f2d-b419-dccd10f0bd51"
      },
      "source": [
        "!pip install qiskit"
      ],
      "id": "zU0dLKiHFf2j",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-0.32.1.tar.gz (13 kB)\n",
            "Collecting qiskit-terra==0.18.3\n",
            "  Downloading qiskit_terra-0.18.3-cp37-cp37m-manylinux2010_x86_64.whl (6.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 7.2 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.9.1\n",
            "  Downloading qiskit_aer-0.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.9 MB 499 kB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.18.1\n",
            "  Downloading qiskit_ibmq_provider-0.18.1-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 55.2 MB/s \n",
            "\u001b[?25hCollecting qiskit-ignis==0.6.0\n",
            "  Downloading qiskit_ignis-0.6.0-py3-none-any.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 44.5 MB/s \n",
            "\u001b[?25hCollecting qiskit-aqua==0.9.5\n",
            "  Downloading qiskit_aqua-0.9.5-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1->qiskit) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1->qiskit) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (5.4.8)\n",
            "Collecting dlx<=1.0.4\n",
            "  Downloading dlx-1.0.4.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: h5py<3.3.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (3.1.0)\n",
            "Collecting quandl\n",
            "  Downloading Quandl-3.7.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (1.7.1)\n",
            "Collecting docplex>=2.21.207\n",
            "  Downloading docplex-2.22.213.tar.gz (634 kB)\n",
            "\u001b[K     |████████████████████████████████| 634 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastdtw<=0.3.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (1.1.5)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (57.4.0)\n",
            "Collecting yfinance>=0.1.62\n",
            "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
            "Collecting retworkx>=0.8.0\n",
            "  Downloading retworkx-0.10.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5->qiskit) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (2.23.0)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1->qiskit) (2.8.2)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting python-constraint>=1.4\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "Collecting symengine>0.7\n",
            "  Downloading symengine-0.8.1-cp37-cp37m-manylinux2010_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3->qiskit) (2.6.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3->qiskit) (0.3.4)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 42.5 MB/s \n",
            "\u001b[?25hCollecting fastjsonschema>=2.10\n",
            "  Downloading fastjsonschema-2.15.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from docplex>=2.21.207->qiskit-aqua==0.9.5->qiskit) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<3.3.0->qiskit-aqua==0.9.5->qiskit) (1.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.1->qiskit) (2.10)\n",
            "Collecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.1->qiskit) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.1->qiskit) (2.21)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->qiskit-aqua==0.9.5->qiskit) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->qiskit-aqua==0.9.5->qiskit) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-aqua==0.9.5->qiskit) (1.2.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance>=0.1.62->qiskit-aqua==0.9.5->qiskit) (0.0.10)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->qiskit-aqua==0.9.5->qiskit) (2018.9)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from quandl->qiskit-aqua==0.9.5->qiskit) (8.12.0)\n",
            "Collecting inflection>=0.3.1\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Building wheels for collected packages: qiskit, dlx, docplex, python-constraint\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.32.1-py3-none-any.whl size=11776 sha256=d70f4e50b8ab84eabd662f4b9a91b2da056029717bf5d4672a9d38da31a1e61e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/62/0a/c53eda1ead41c137c47c9730bc2771a8367b1ce00fb64e8cc6\n",
            "  Building wheel for dlx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlx: filename=dlx-1.0.4-py3-none-any.whl size=5719 sha256=67da71313e4dbc4de7d40821ebae9938e2bb87e38fa77d9242a315f1f9f14cb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/55/c8/dc61e772445a566b7608a476d151e9dcaf4e092b01b0c4bc3c\n",
            "  Building wheel for docplex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docplex: filename=docplex-2.22.213-py3-none-any.whl size=696881 sha256=f9c11b932c15395edb8b66d2351d66a236b426bdb6a92100470985da782abeb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/69/6b/1375c68a5b7ff94c40263b151c86f58bd72200bf0c465b5ba3\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=b24f4fa51b0e95be6df0a4b04468887c316e727be808b40c8602cf56edf6fe80\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
            "Successfully built qiskit dlx docplex python-constraint\n",
            "Installing collected packages: tweedledum, symengine, retworkx, python-constraint, ply, fastjsonschema, qiskit-terra, ntlm-auth, lxml, inflection, cryptography, yfinance, websocket-client, requests-ntlm, quandl, qiskit-ignis, docplex, dlx, qiskit-ibmq-provider, qiskit-aqua, qiskit-aer, qiskit\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed cryptography-36.0.0 dlx-1.0.4 docplex-2.22.213 fastjsonschema-2.15.1 inflection-0.5.1 lxml-4.6.4 ntlm-auth-1.5.0 ply-3.11 python-constraint-1.4.0 qiskit-0.32.1 qiskit-aer-0.9.1 qiskit-aqua-0.9.5 qiskit-ibmq-provider-0.18.1 qiskit-ignis-0.6.0 qiskit-terra-0.18.3 quandl-3.7.0 requests-ntlm-1.1.0 retworkx-0.10.2 symengine-0.8.1 tweedledum-1.1.1 websocket-client-1.2.1 yfinance-0.1.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b641b47-223d-4c7b-83da-22fafeb1ce30"
      },
      "source": [
        "#from IPython.core.debugger import set_trace\n",
        "import numpy as np\n",
        "\n",
        "# Importing standard Qiskit libraries\n",
        "from qiskit import QuantumCircuit, transpile, Aer, IBMQ\n",
        "from qiskit.tools.jupyter import *\n",
        "from qiskit.visualization import *\n",
        "#from ibm_quantum_widgets import *\n",
        "from qiskit.providers.aer import QasmSimulator\n",
        "\n",
        "# Loading your IBM Quantum account(s)\n",
        "#provider = IBMQ.load_account()"
      ],
      "id": "4b641b47-223d-4c7b-83da-22fafeb1ce30",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06531ccd-1b9f-4f08-8c98-d0cc9315f3f1"
      },
      "source": [
        "#Custom library\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "#sys.path.append(\"../Qiskit_Dynamic_Modelling\")\n",
        "#sys.path.append(\"./modelQ\")\n",
        "#sys.path.append(\"./dynamicsQ\")\n",
        "sys.path.append(\"./sample_data\")\n",
        "\n",
        "from visualize import *\n",
        "from ode_solver import *\n",
        "#from network import *\n",
        "from dataloader import *\n",
        "from lagrangian import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torchsummary import summary\n",
        "\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import qiskit\n",
        "from qiskit.circuit.random import random_circuit\n",
        "from qiskit import transpile, assemble"
      ],
      "id": "06531ccd-1b9f-4f08-8c98-d0cc9315f3f1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ce742d-dff9-4cdc-b476-b0dad45658c6",
        "outputId": "f3265c7e-6a3e-405f-d75a-f5ebc50a6a52"
      },
      "source": [
        "print(\"--- Loading training and test data... ---\")\n",
        "train_data = np.load('/content/sample_data/train_dataset.npz')\n",
        "train_inputs = train_data[\"input\"]\n",
        "train_labels = train_data[\"labels\"]\n",
        "\n",
        "X_train = train_inputs[:1000]\n",
        "y_train = train_labels[:1000]\n",
        "\n",
        "#train_dataset = DynamicsDataset(train_inputs, train_labels)\n",
        "train_dataset = DynamicsDataset(X_train, y_train)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                 batch_size=1,\n",
        "                                                 shuffle=True,\n",
        "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
        "                                                 pin_memory=True,\n",
        "                                                 num_workers=1)\n",
        "test_data = np.load('/content/sample_data/val_dataset.npz')\n",
        "test_inputs = train_data[\"input\"]\n",
        "test_labels = train_data[\"labels\"]\n",
        "X_test = test_inputs[:1000]\n",
        "y_test = test_labels[:1000]\n",
        "\n",
        "test_dataset = DynamicsDataset(X_test, y_test)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                 batch_size=1,\n",
        "                                                 shuffle=False,\n",
        "                                                 collate_fn=DynamicsDataset.collate_fn,\n",
        "                                                 pin_memory=True,\n",
        "                                                 num_workers=1)\n",
        "print(\"--- Loading training and test data completed ---\")"
      ],
      "id": "f3ce742d-dff9-4cdc-b476-b0dad45658c6",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading training and test data... ---\n",
            "--- Loading training and test data completed ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4bb110b-3976-4cf4-aea4-3f554080bc40",
        "outputId": "749014ea-d199-4ffa-ca82-82771faab42d"
      },
      "source": [
        "for (X_train, y_train) in train_dataloader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    print('X_train:', X_train)\n",
        "    print('y_train:', y_train)\n",
        "    break\n",
        "\n",
        "for (X_test, y_test) in test_dataloader:\n",
        "    print('X_test:', X_test.size(), 'type:', X_test.type())\n",
        "    print('y_test:', y_test.size(), 'type:', y_test.type())\n",
        "    print('X_test:', X_test)\n",
        "    print('y_test:', y_test)\n",
        "    break"
      ],
      "id": "b4bb110b-3976-4cf4-aea4-3f554080bc40",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "y_train: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "X_train: tensor([[ 3.0396,  2.1699,  0.1009, -0.1473]], dtype=torch.float64)\n",
            "y_train: tensor([[ 0.1009, -0.1473,  2.0250, -9.3997]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./sample_data/dataloader.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  batch_x = torch.as_tensor(batch_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "y_test: torch.Size([1, 4]) type: torch.DoubleTensor\n",
            "X_test: tensor([[ 1.9537,  0.2797, -0.0780, -0.2268]], dtype=torch.float64)\n",
            "y_test: tensor([[-0.0780, -0.2268, -9.3138, -3.6618]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88f7c05-88f9-4f00-87cd-7c841835ed03"
      },
      "source": [
        "class QuantumCircuit:\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "        self.theta = qiskit.circuit.Parameter('theta')\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta, all_qubits)\n",
        "        \n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        #set_trace()\n",
        "        #print('cRun:',thetas)\n",
        "        List = [thetas]\n",
        "        t_qc = transpile(self._circuit,\n",
        "                         self.backend)\n",
        "        qobj = assemble(t_qc,\n",
        "                        shots=self.shots,\n",
        "                        parameter_binds = [{self.theta: theta} for theta in List])\n",
        "        #set_trace()\n",
        "        job = self.backend.run(qobj)\n",
        "        result = job.result().get_counts()\n",
        "        \n",
        "        counts = np.array(list(result.values()))\n",
        "        states = np.array(list(result.keys())).astype(float)\n",
        "        \n",
        "        # Compute probabilities for each state\n",
        "        probabilities = counts / self.shots\n",
        "        # Get state expectation\n",
        "        expectation = np.sum(states * probabilities)\n",
        "        \n",
        "        return np.array([expectation])"
      ],
      "id": "d88f7c05-88f9-4f00-87cd-7c841835ed03",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "83916b6d-f732-4ac2-88b1-3a47c4e3c858",
        "outputId": "ec38272a-6d0d-4c3e-848c-4e9e97a77ebd"
      },
      "source": [
        "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
        "\n",
        "circuit = QuantumCircuit(1, simulator, 100)\n",
        "#data = [2.1757166385650635]\n",
        "print('Expected value for rotation pi {}'.format(circuit.run(2.1757166385650635)))\n",
        "#print('Expected value for rotation pi {}'.format(circuit.run([1.4173])))\n",
        "circuit._circuit.draw()"
      ],
      "id": "83916b6d-f732-4ac2-88b1-3a47c4e3c858",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/qiskit/utils/deprecation.py:62: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected value for rotation pi [0.87]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "   q_0: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 </pre>"
            ],
            "text/plain": [
              "        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "   q_0: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069a1e0d-f600-4109-ae0b-57ec65befdea"
      },
      "source": [
        "class HybridFunction(Function):\n",
        "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, input, quantum_circuit, shift):\n",
        "        \"\"\" Forward pass computation \"\"\"\n",
        "        ##print('hFor:', input)\n",
        "        #print('hFor1:', input[0])\n",
        "        #print('hFor2:', input[0].tolist())\n",
        "        ctx.shift = shift\n",
        "        ctx.quantum_circuit = quantum_circuit\n",
        "        #expectation_z = []\n",
        "        #for i in range(len(input)):\n",
        "        #    expectation_z.append(ctx.quantum_circuit.run(input[i].tolist()))\n",
        "        #print('expectation_z',expectation_z)\n",
        "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
        "        result = torch.tensor([expectation_z])\n",
        "        #result = torch.tensor(expectation_z)\n",
        "        ctx.save_for_backward(input, result)\n",
        "\n",
        "        return result\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\" Backward pass computation \"\"\"\n",
        "        input, expectation_z = ctx.saved_tensors\n",
        "        input_list = np.array(input.tolist())\n",
        "        \n",
        "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
        "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
        "        \n",
        "        gradients = []\n",
        "        for i in range(len(input_list)):\n",
        "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
        "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
        "            \n",
        "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
        "            gradients.append(gradient)\n",
        "        gradients = np.array([gradients]).T\n",
        "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
        "\n",
        "class Hybrid(nn.Module):\n",
        "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
        "    \n",
        "    def __init__(self, backend, shots, shift):\n",
        "        super(Hybrid, self).__init__()\n",
        "        self.quantum_circuit = QuantumCircuit(1, backend, shots)\n",
        "        self.shift = shift\n",
        "        \n",
        "    def forward(self, input):\n",
        "        #print('3',input)\n",
        "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
      ],
      "id": "069a1e0d-f600-4109-ae0b-57ec65befdea",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35542acb-5d1a-49c0-a68b-34ac5abfa671"
      },
      "source": [
        "class LagrangianNeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, D_in, hidden_list, D_out):\n",
        "        \"\"\"\n",
        "        Neural Network used to approximate a paramaterized system lagrangian\n",
        "        \"\"\"\n",
        "        super(LagrangianNeuralNetwork, self).__init__()\n",
        "        self.model_layers = torch.nn.ModuleList()\n",
        "\n",
        "        # input layer\n",
        "        self.model_layers.append(torch.nn.Linear(D_in, hidden_list[0]))\n",
        "        # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[0]))\n",
        "        self.model_layers.append(torch.nn.Softplus())\n",
        "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
        "        # add all hiden layers\n",
        "        for i in range(1, len(hidden_list)):\n",
        "            self.model_layers.append(torch.nn.Linear(hidden_list[i-1], hidden_list[i]))\n",
        "            # self.model_layers.append(torch.nn.BatchNorm1d(hidden_list[i]))\n",
        "            self.model_layers.append(torch.nn.Softplus())\n",
        "\n",
        "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
        "        #self.model_layers.append(Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2))\n",
        "        # output layer\n",
        "        self.model_layers.append(torch.nn.Linear(hidden_list[-1], D_out))\n",
        "        self.model_layers.append(torch.nn.Softplus())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        applies all of the model layers, and returns the single output value,\n",
        "        which in this case is the lagrangian of the system, representing the\n",
        "        total energy\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        #print(\"2 \", x)\n",
        "        for layer in self.model_layers:\n",
        "            #print(len(self.model_layers))\n",
        "            #if(count >= (len(self.model_layers) - 3)):\n",
        "                #print(count)\n",
        "                #print(x)\n",
        "            #    x = self.hybrid(x)\n",
        "                #print(x)\n",
        "            x = layer(x)\n",
        "            #print(count)\n",
        "            #count = count + 1\n",
        "            #x = self.hybrid(x)\n",
        "        #print('c', x)                \n",
        "        x = self.hybrid(x)\n",
        "        #print('q', x)\n",
        "        return x"
      ],
      "id": "35542acb-5d1a-49c0-a68b-34ac5abfa671",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d2bedba-0e01-4403-8535-b54d702ca1cc",
        "outputId": "50c72010-2701-4b78-ca29-462cf081bf13"
      },
      "source": [
        "# determine device\n",
        "print(\"--- Checking for CUDA Device... ---\")\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "id": "9d2bedba-0e01-4403-8535-b54d702ca1cc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking for CUDA Device... ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvkMDk12QBHo",
        "outputId": "17074a46-ae49-4fb5-d393-ea02aae3fb9b"
      },
      "source": [
        "# organize data\n",
        "input_size = train_inputs.shape[1]\n",
        "output_size = 1  # for all lagrangian systems, output should be just a scalar energy value\n",
        "\n",
        "# build model\n",
        "print(\"--- Constructing Model... ---\")\n",
        "D_in = input_size  # state size\n",
        "# hidden_list = [D_in, 256, 256, 256, 256, 256]\n",
        "hidden_list = [D_in, 32, 64, 128, 256, 512, 256, 128, 64, 32]\n",
        "D_out = output_size\n",
        "lnn_model = LagrangianNeuralNetwork(D_in, hidden_list, D_out)\n",
        "#summary(lnn_model, (1, 28, 28), device='cpu')\n",
        "# set up training parameters\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "momentum = 0.9\n",
        "num_epochs = 20\n",
        "optimizer = torch.optim.Adam(lnn_model.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=weight_decay)\n",
        "\n",
        "if os.path.isfile(\"model_weights.pth\"):\n",
        "    print(\"Re-loading existing weights!\")\n",
        "    checkpoint = torch.load(\"model_weights.pth\")\n",
        "    lnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# ensure model is in train mode so gradients are properly calculated\n",
        "lnn_model.train()\n",
        "# load device to either GPU or CPU depending on hardware\n",
        "lnn_model.to(device)\n",
        "\n",
        "# set up loss function\n",
        "loss_fcn = torch.nn.MSELoss()\n",
        "\n",
        "# set up GradScaler to improve run speed\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "id": "LvkMDk12QBHo",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Constructing Model... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56359ff6-9cbd-4491-b2ab-9001b5342048",
        "outputId": "957ffef7-d74b-4dd3-acbb-f69620cea995"
      },
      "source": [
        "import time\n",
        "print(\"--- Beginning Training! ---\")\n",
        "loss_listQCQ = []\n",
        "lnn_model.train()\n",
        "startTimeQCQ = time.time()\n",
        "print('Training Start Time (in sec) : ',(startTimeQCQ))\n",
        "print('Training Start Time : ',(time.asctime( time.localtime(time.time()) )))\n",
        "for epoch in range(num_epochs):\n",
        "    total_lossQCQ = []\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        for p in lnn_model.parameters(): p.grad = None\n",
        "        # Forward pass\n",
        "        #output = model(data)\n",
        "        # Calculating loss\n",
        "        #loss = loss_func(output, target)\n",
        "        # output from model is the energy calculated from the parameterized lagrangian\n",
        "        #print('1',data)\n",
        "        #print('1',data.detach().numpy())\n",
        "        #for val in enumerate(data.detach().numpy()):\n",
        "        #    print(val)\n",
        "        Listk = []\n",
        "        for val in data.detach().numpy():\n",
        "            #print(val)            \n",
        "            for i in range(len(val)):\n",
        "                #print(val[i])\n",
        "                qcr = circuit.run(val[i])\n",
        "                #print(qcr[0])\n",
        "                Listk.append(qcr[0])\n",
        "                #print(Listk)\n",
        "                \n",
        "        ListTarget = []\n",
        "        #print(target)\n",
        "        for valT in target.detach().numpy():\n",
        "            #print(val)            \n",
        "            for j in range(len(valT)):\n",
        "                #print(val[i])\n",
        "                qcrT = circuit.run(valT[j])\n",
        "                #print(qcr[0])\n",
        "                ListTarget.append(qcrT[0])\n",
        "                #print(ListTarget)\n",
        "        targetData = torch.tensor(ListTarget)\n",
        "        data = torch.squeeze(torch.tensor(Listk))\n",
        "        #data = torch.squeeze(data)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            target_pred = solve_euler_lagrange(lnn_model.forward, data.float())\n",
        "            #print('1',target_pred)\n",
        "            #print('2',target.float())\n",
        "            loss = loss_fcn(target_pred.unsqueeze(0), targetData.float())\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        # Optimize the weights\n",
        "        scaler.step(optimizer)\n",
        "        # update the scale for next iteration\n",
        "        scaler.update()\n",
        "\n",
        "        #print(\"Iter Num: \", batch_idx)\n",
        "        '''\n",
        "        if (batch_idx == 10):\n",
        "            #print(\"Iter Num: \", batch_idx)\n",
        "            break\n",
        "        '''\n",
        "        #print(\"Iter Num: \", len(train_dataloader))\n",
        "        #print(\"Iter Num: \", batch_idx)\n",
        "        total_lossQCQ.append(loss.item())\n",
        "    loss_listQCQ.append(sum(total_lossQCQ)/len(total_lossQCQ))\n",
        "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
        "        100. * (epoch + 1) / num_epochs, loss_listQCQ[-1]))\n",
        "print('Training End Time (in sec) : ',(time.time()))\n",
        "print('Total training time (in sec)', ((time.time() - startTimeQCQ)))\n",
        "print('Training End Time',(time.asctime( time.localtime(time.time()) )))\n",
        "print('end')"
      ],
      "id": "56359ff6-9cbd-4491-b2ab-9001b5342048",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Beginning Training! ---\n",
            "Training Start Time (in sec) :  1638408193.2204015\n",
            "Training Start Time :  Thu Dec  2 01:23:13 2021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/qiskit/utils/deprecation.py:62: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training [5%]\tLoss: 0.3200\n",
            "Training [10%]\tLoss: 0.1100\n",
            "Training [15%]\tLoss: 0.0831\n",
            "Training [20%]\tLoss: 0.0826\n",
            "Training [25%]\tLoss: 0.0772\n",
            "Training [30%]\tLoss: 0.0754\n",
            "Training [35%]\tLoss: 0.0745\n",
            "Training [40%]\tLoss: 0.0702\n",
            "Training [45%]\tLoss: 0.0690\n",
            "Training [50%]\tLoss: 0.0677\n",
            "Training [55%]\tLoss: 0.0672\n",
            "Training [60%]\tLoss: 0.0657\n",
            "Training [65%]\tLoss: 0.0659\n",
            "Training [70%]\tLoss: 0.0645\n",
            "Training [75%]\tLoss: 0.0641\n",
            "Training [80%]\tLoss: 0.0646\n",
            "Training [85%]\tLoss: 0.0652\n",
            "Training [90%]\tLoss: 0.0631\n",
            "Training [95%]\tLoss: 0.0633\n",
            "Training [100%]\tLoss: 0.0627\n",
            "Training End Time (in sec) :  1638413166.1414444\n",
            "Total training time (in sec) 4972.921623706818\n",
            "Training End Time Thu Dec  2 02:46:06 2021\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4aa85bc5-b9d3-49a3-9c42-7b960831a5c8",
        "outputId": "515179e7-f746-4cf3-b4c9-25b817bc21d2"
      },
      "source": [
        "plt.plot(loss_listQCQ)\n",
        "plt.title('Hybrid LQNN Q-C-Q Training')\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Loss')\n",
        "#plt.show()"
      ],
      "id": "4aa85bc5-b9d3-49a3-9c42-7b960831a5c8",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b07d24fd-d4b8-4212-9071-1f2e78a3413b",
        "outputId": "01f799ce-cd9e-4f38-b1b6-d288e3fcf6cc"
      },
      "source": [
        "print(\"--- Beginning Test! ---\")\n",
        "lnn_model.eval()\n",
        "total_losstestQCQ = []\n",
        "correctQCQ = 0\n",
        "for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data = torch.squeeze(data)\n",
        "    with torch.cuda.amp.autocast():\n",
        "        target_pred = solve_euler_lagrange(lnn_model.forward, data.float())\n",
        "        #print(target_pred)\n",
        "        #print(target)\n",
        "        correctQCQ += target_pred.eq(target.view_as(target_pred)).sum().item()\n",
        "        loss = loss_fcn(target_pred.unsqueeze(0), target.float())        \n",
        "    total_losstestQCQ.append(loss.item())\n",
        "batch_size = 1\n",
        "print('Performance on test data:[{:.0f}%]\\tLoss: {:.4f}\\tAccuracy: {:.1f}%'.format(\n",
        "    100. * (epoch + 1) / num_epochs,\n",
        "    sum(total_losstestQCQ) / len(total_losstestQCQ),\n",
        "    correctQCQ / len(test_dataloader) * 100 / batch_size)\n",
        "    )\n",
        "\n",
        "print('end')"
      ],
      "id": "b07d24fd-d4b8-4212-9071-1f2e78a3413b",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Beginning Test! ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "/usr/local/lib/python3.7/dist-packages/qiskit/utils/deprecation.py:62: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance on test data:[100%]\tLoss: 22.0757\tAccuracy: 0.0%\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04928beb-aa4d-48e1-a823-e1a61b9ca15d"
      },
      "source": [
        ""
      ],
      "id": "04928beb-aa4d-48e1-a823-e1a61b9ca15d",
      "execution_count": null,
      "outputs": []
    }
  ]
}